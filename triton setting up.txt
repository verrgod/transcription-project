docker login nvcr.io
docker pull nvcr.io/nvidia/tritonserver:24.12-vllm-python-py3

(run on powershell- image building using faster-whisper-docker dockerfile)
docker build -t my-triton-faster-whisper:latest .

(run on the built image)
docker run --rm --gpus all -it `
  --privileged `
  -p8000:8000 -p8001:8001 -p8002:8002 `
  --shm-size=1G --ulimit memlock=-1 --ulimit stack=67108864 `
  -v "$PWD\models:/models" `
  my-triton-faster-whisper:latest `
  tritonserver --model-repository=/models

(above for testing, code now able to run)
docker compose build
docker compose up 
(once containers up, media-processor-1 should be waiting for messages)

nvidia-smi
docker version

(check server status)
curl -v localhost:8000/v2/health/ready 

(run docker-compose.yml to setup containers, 8088 ksqldb)
docker compose up
docker exec -it ksqldb-cli ksql http://ksqldb-server:8088

(ksql stream)
CREATE STREAM minio_media_events (
    eventName STRING,
    key STRING,
    records ARRAY<STRUCT<
        eventTime STRING,
        eventName STRING,
        s3 STRUCT<
            bucket STRUCT<name STRING>,
            object STRUCT<
                key STRING,
                `size` BIGINT,  -- Use backticks or rename it
                contentType STRING
            >
        >
    >>
) WITH (
    KAFKA_TOPIC = 'minio-events-v1',
    VALUE_FORMAT = 'JSON',
    PARTITIONS = 10
);

CREATE STREAM transformed_media_events WITH (
    KAFKA_TOPIC = 'transformed-minio-events',
    VALUE_FORMAT = 'JSON',
    PARTITIONS = 1
) AS
SELECT
    eventName,
    records[1]->eventTime AS event_time,
    records[1]->s3->bucket->name AS bucket_name,
    records[1]->s3->object->key AS file_name,
    records[1]->s3->object->`size` AS object_size,  -- Use backticks or rename
    records[1]->s3->object->contentType AS content_type
FROM minio_media_events
EMIT CHANGES;

(get --network=NETWORK NAME by doing docker network ls)
(docker network inspect NETWORK name to check if kafka running if got connectivity issues)
(once fine run this)
docker run -it --network=transcription-project_default edenhill/kcat:1.7.1 -b kafka:9092 -L

(check if kafka stream monitoring minio bucket)
docker run --rm -it --network=transcription-project_default edenhill/kcat:1.7.1 -b kafka:9092 -t minio-events-v1 -C


curl -v --location POST 'http://localhost:8000/v2/models/faster-whisper-large-v3/infer' \
--header 'Content-Type: application/octet-stream' \
--data-binary @infer.json \
--data-binary @transcribing_1.mp3 \
-H "Inference-Header-Content-Length: 0" -o resp.txt

curl -v --location --request POST 'http://localhost:8000/v2/models/faster-whisper-large-v3/infer' \
--header 'Content-Type: application/octet-stream' \
--data-binary @harvard.wav \
-H "Inference-Header-Content-Length: 0" -o resp.txt

(check if kafka can read minio)
docker run --rm -it --network=transcription-project_default edenhill/kcat:1.7.1 \
  -b kafka:9092 -t minio-events-v1 -C

docker run -it --rm -p 3000:3000 -v C:\Users\Vernon\Desktop\transcription-project\frontend\audio_uploader:/app -w /app node:22-alpine sh
npm start